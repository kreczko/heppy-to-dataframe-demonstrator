#! /usr/bin/env python
"""
step7_htcondor_all_components/run.py
Run over all components of a heppy dataset, using htcondor jobs, weighting
events by the genWeight value and identifying the source sample in the
dataframe
"""

from alphatwirl.binning import Binning, Echo
from alphatwirl.configure import TableConfigCompleter, TableFileNameComposer2
from alphatwirl_interface.completions import complete, to_null_collector_pairs
from alphatwirl_interface.cut_flows import cut_flow_with_counter
from alphatwirl_interface.scribblers import  DivideNumpyArrays, ComponentName
from alphatwirl_interface.weighters import  WeightCalculatorProduct
from alphatwirl_interface.heppy.runners import  build_job_manager
import ROOT
import pprint

def main(in_path, out_dir, tree_name="tree", isdata=False, components=["all"]):
    # Get the input file
    mgr = build_job_manager(out_dir, in_path, isdata=isdata,
                            parallel_mode="htcondor", force=True)

    # Setup the scribblers to add objects to event
    scribblers = make_scribblers()

    # Prepare the event selection
    event_selection = cut_flow()

    # Describe the output dataframe
    df_cfg = dataframe_config()

    # Run alphatwirl to build the dataframe
    dataframes = summarize(mgr, df_cfg, event_selection, scribblers, components)

    # Print everything out
    print "Number of dataframes created:",len(dataframes)
    for df in dataframes:
        print type(df)
        pprint.pprint(df)


def make_scribblers():
    '''
        Create scribblers. Scribblers are like EDProducers, they take some
        inputs and produce new variables
    '''
    scribblers = [
        # adding the (HEPPY) component name which maps
        # event.component.name to componentName column
        ComponentName(),
        # take mht40_pt and divide by met_pt
        # input variables must be of the same lenght!
        DivideNumpyArrays(['mht40_pt', 'met_pt'],'MhtOverMet'),
    ]
    # pair the scribblers with "NULL" collectors
    return to_null_collector_pairs(scribblers)


def cut_flow():
    '''
        Defines all cuts that will be applied to input data
    '''
    # dictionary of selection criteria
    # the 'All' key denotes that an event has to pass all the listed cuts
    # other options are Any (or) and Not (inverse)
    # event (`ev`) refers to a single entry in the input tree
    # names and indices after that are the branch names
    event_selection = dict(All = (
        'ev : ev.cutflowId[0] == 1',
        'ev : ev.nIsoTracksVeto[0] <= 0',
        'ev : ev.nJet40[0] >= 2',
        'ev : ev.ht40[0] >= 200',
        'ev : ev.nJet100[0] >= 1',
        'ev : ev.nJet40failedId[0] == 0',
        'ev : ev.nJet40Fwd[0] == 0',
        'ev : -2.5 < ev.jet_eta[0] < 2.5',
        'ev : 0.1 <= ev.jet_chHEF[0] < 0.95',
        'ev : 130 <= ev.mht40_pt[0]',
        # using variable generated by a scribbler
        'ev : ev.MhtOverMet[0] < 1.25',
    ))

    # create a reader + collector pair for the cutflow
    # the collector will reject events and store the cut flow into a text file
    return cut_flow_with_counter(event_selection, "cut_flow_table.txt")


def dataframe_config():
    '''
        Creates the definition/config of the data frame (DF).

        :return a list of DF configs
    '''
    # Set up categorical binning
    # use simple binning for HT and N_jet
    htbin = Binning(boundaries=[200, 400, 600, 900, 1200])
    njetbin = Binning(boundaries=[1, 2, 3, 4, 5, 6])
    # Echo simply returns the value it gets
    nbjetbin = Echo()
    # explicit version
    # nbjetbin = Echo(nextFunc = lambda x: x+1, valid = lambda x: True)
    # add HEPPY component name binning, has no rules to produce the next bin
    # component names are strings!
    component = Echo(nextFunc=None)

    # a list of DF configs
    df_configs = [
        dict(
            # which tree branches to read in
            keyAttrNames=('componentName', 'ht40', 'nJet40', 'nBJet40'),
            # which columns in the DF they should be mapped to
            keyOutColumnNames=('component', 'htbin', 'njetbin', 'nbjetbin'),
            # the binning for the categories
            binnings=(component, htbin, njetbin, nbjetbin),
            # list of weight branches that are multiplied together for the
            # final event weight
            weight=WeightCalculatorProduct(['genWeight'])
        ),
    ]

    return df_configs


def summarize(mgr, df_cfg, event_selection, scribblers, max_events = -1):
    '''
        Summarise the data in the tree into the data frames (DFs) given in
        df_cfg.

        :param mgr: HEPPY job manager
        :param df_cfg(list): list of DF definitions
        :param event_selection: pairs of event selections and collectors
        :param scribblers: pairs of scribblers and empty collectors which
                           create new event content
        :param components: list of heppy component names to summarize
    '''

    reader_collector_pairs = scribblers + event_selection

    # setting up defaults to complete the provided DF configs
    tableConfigCompleter = TableConfigCompleter(
        # using a composer to create a predictable output file name
        # based on the names of the output columns
        createOutFileName=TableFileNameComposer2(default_prefix='tbl_n')
    )
    # combine configs and completers
    reader_collector_pairs += complete(df_cfg, tableConfigCompleter)

    return mgr.run(reader_collector_pairs, components=components)


def process_options():
    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter
    import sys
    import os
    parser = ArgumentParser(description=__doc__,
                            formatter_class=ArgumentDefaultsHelpFormatter)
    parser.add_argument("in_path",
                        help="The path to the input data")
    parser.add_argument("-o", "--out_dir",
                        help="The path to an output directory, which should exist",
                        default=os.getcwd())
    parser.add_argument('--mc', action='store_const', dest='isdata',
                        const=False, default=False, help='Input events are from MC')
    parser.add_argument('--data', action='store_const', dest='isdata',
                        const=True, help='Input events are from Data')
    parser.add_argument('--components', default=["all"],
                        help="""
                             Select which Heppy components to read. \
                                Use "all" to read everything""")
    return parser.parse_args()


if __name__ == "__main__":
    args = process_options()
    main(**args.__dict__)
